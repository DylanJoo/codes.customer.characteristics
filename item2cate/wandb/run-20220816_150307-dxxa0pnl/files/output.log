  0%|          | 0/10000 [00:00<?, ?it/s]/home/jhju/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:990: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using non-full backward hooks on a Module that does not return a "
/home/jhju/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
  0%|          | 1/10000 [00:00<26:02,  6.40it/s]  0%|          | 2/10000 [00:00<21:07,  7.89it/s]  0%|          | 3/10000 [00:00<20:12,  8.25it/s]  0%|          | 5/10000 [00:00<17:04,  9.76it/s]  0%|          | 7/10000 [00:00<15:41, 10.62it/s]  0%|          | 9/10000 [00:00<15:41, 10.61it/s]  0%|          | 11/10000 [00:01<15:14, 10.92it/s]  0%|          | 13/10000 [00:01<15:05, 11.03it/s]  0%|          | 15/10000 [00:01<14:45, 11.27it/s]  0%|          | 17/10000 [00:01<14:29, 11.48it/s]  0%|          | 19/10000 [00:01<14:31, 11.45it/s]  0%|          | 21/10000 [00:01<14:27, 11.50it/s]  0%|          | 23/10000 [00:02<14:27, 11.50it/s]  0%|          | 25/10000 [00:02<15:16, 10.89it/s]  0%|          | 27/10000 [00:02<14:50, 11.20it/s]  0%|          | 29/10000 [00:02<14:37, 11.36it/s]  0%|          | 31/10000 [00:02<14:26, 11.51it/s]  0%|          | 33/10000 [00:03<14:25, 11.51it/s]  0%|          | 35/10000 [00:03<15:16, 10.87it/s]  0%|          | 37/10000 [00:03<15:39, 10.61it/s]  0%|          | 39/10000 [00:03<15:20, 10.82it/s]  0%|          | 41/10000 [00:03<15:35, 10.65it/s]  0%|          | 43/10000 [00:03<15:20, 10.82it/s]  0%|          | 45/10000 [00:04<14:45, 11.24it/s]  0%|          | 47/10000 [00:04<14:51, 11.17it/s]  0%|          | 49/10000 [00:04<14:31, 11.42it/s]  1%|          | 51/10000 [00:04<15:20, 10.81it/s]  1%|          | 53/10000 [00:04<14:49, 11.19it/s]  1%|          | 55/10000 [00:05<15:21, 10.79it/s]  1%|          | 57/10000 [00:05<15:03, 11.00it/s]  1%|          | 59/10000 [00:05<15:06, 10.96it/s]  1%|          | 61/10000 [00:05<14:51, 11.15it/s]  1%|          | 63/10000 [00:05<15:01, 11.02it/s]  1%|          | 65/10000 [00:05<14:49, 11.17it/s]  1%|          | 67/10000 [00:06<14:24, 11.48it/s]  1%|          | 69/10000 [00:06<14:15, 11.60it/s]  1%|          | 71/10000 [00:06<14:19, 11.55it/s]  1%|          | 73/10000 [00:06<14:10, 11.67it/s]  1%|          | 75/10000 [00:06<14:04, 11.76it/s]  1%|          | 77/10000 [00:06<14:16, 11.59it/s]  1%|          | 79/10000 [00:07<14:08, 11.70it/s]  1%|          | 81/10000 [00:07<14:18, 11.56it/s]  1%|          | 83/10000 [00:07<14:04, 11.75it/s]  1%|          | 85/10000 [00:07<14:03, 11.75it/s]  1%|          | 87/10000 [00:07<13:46, 12.00it/s]  1%|          | 89/10000 [00:07<14:06, 11.71it/s]  1%|          | 91/10000 [00:08<13:56, 11.85it/s]  1%|          | 93/10000 [00:08<14:07, 11.70it/s]  1%|          | 95/10000 [00:08<14:05, 11.71it/s]  1%|          | 97/10000 [00:08<15:06, 10.92it/s]  1%|          | 99/10000 [00:08<15:00, 11.00it/s]  1%|          | 101/10000 [00:09<14:33, 11.33it/s]  1%|          | 103/10000 [00:09<15:53, 10.38it/s]  1%|          | 105/10000 [00:09<15:55, 10.35it/s]  1%|          | 107/10000 [00:09<15:27, 10.66it/s]  1%|          | 109/10000 [00:09<14:47, 11.14it/s]  1%|          | 111/10000 [00:09<14:41, 11.22it/s]  1%|          | 113/10000 [00:10<14:50, 11.10it/s]  1%|          | 115/10000 [00:10<14:41, 11.22it/s]  1%|          | 117/10000 [00:10<14:50, 11.10it/s]  1%|          | 119/10000 [00:10<14:46, 11.15it/s]  1%|          | 121/10000 [00:10<14:26, 11.41it/s]  1%|          | 123/10000 [00:11<14:25, 11.41it/s]  1%|▏         | 125/10000 [00:11<14:42, 11.19it/s]  1%|▏         | 127/10000 [00:11<15:23, 10.69it/s]  1%|▏         | 129/10000 [00:11<14:58, 10.98it/s]  1%|▏         | 131/10000 [00:11<14:45, 11.15it/s]  1%|▏         | 133/10000 [00:11<14:40, 11.21it/s]  1%|▏         | 135/10000 [00:12<15:21, 10.71it/s]  1%|▏         | 137/10000 [00:12<15:00, 10.96it/s]  1%|▏         | 139/10000 [00:12<14:44, 11.15it/s]  1%|▏         | 141/10000 [00:12<14:15, 11.53it/s]  1%|▏         | 143/10000 [00:12<15:00, 10.95it/s]  1%|▏         | 145/10000 [00:13<14:33, 11.29it/s]  1%|▏         | 147/10000 [00:13<14:21, 11.44it/s]  1%|▏         | 149/10000 [00:13<14:37, 11.22it/s]Traceback (most recent call last):
  File "train.py", line 106, in <module>
    main()
  File "train.py", line 101, in main
    results = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)
  File "/home/jhju/.local/lib/python3.8/site-packages/transformers/trainer.py", line 1409, in train
    return inner_training_loop(
  File "/home/jhju/.local/lib/python3.8/site-packages/transformers/trainer.py", line 1718, in _inner_training_loop
    self.optimizer.step()
  File "/home/jhju/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/jhju/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/home/jhju/.local/lib/python3.8/site-packages/transformers/optimization.py", line 360, in step
    exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))
KeyboardInterrupt
